{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Requests and BeautifulSoup to scrape NBA data for players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2000, 2024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape MVP awards table from 2000-2023 and save as an HTML file\n",
    "for year in years:\n",
    "    base_url = f\"https://www.basketball-reference.com/awards/awards_{year}.html\"\n",
    "    data = requests.get(base_url)\n",
    "\n",
    "    with open(f'MVP_Data/{year}.html', 'w+', encoding=\"utf-8\") as f:\n",
    "        f.write(data.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting MVP candidates from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open each HTML file, parse out the table, create pandas dataframe\n",
    "mvp_list = []\n",
    "for year in years:\n",
    "    with open(f\"MVP_data/{year}.html\", errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        remove_header = soup.find(\"tr\", class_='over_header').decompose()\n",
    "        mvp_table = soup.find(id='mvp')\n",
    "        mvp_df = pd.read_html(str(mvp_table))[0]\n",
    "        mvp_df['Year'] = year\n",
    "        mvp_list.append(mvp_df)\n",
    "\n",
    "mvp_data = pd.concat(mvp_list)\n",
    "mvp_data.reset_index(drop=True)\n",
    "mvp_data.to_csv(f'MVP_data/mvp_awards.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting ROY candidates from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "roy_list = []\n",
    "for year in years:\n",
    "    with open(f\"MVP_data/{year}.html\", errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        remove_header = soup.find(\"tr\", class_='over_header').decompose()\n",
    "        roy_table = soup.find(id='roy')\n",
    "        roy_df = pd.read_html(str(roy_table),header=1)[0]\n",
    "        roy_df['Year'] = year\n",
    "        roy_list.append(roy_df)\n",
    "\n",
    "roy_data = pd.concat(roy_list)\n",
    "roy_data.reset_index(drop=True)\n",
    "roy_data.to_csv(f'MVP_data/roy_awards.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting DPOY candidates from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open each HTML file, parse out the table, create pandas dataframe\n",
    "dpoy_list = []\n",
    "for year in years:\n",
    "    with open(f'MVP_data/{year}.html', errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        soupTables = BeautifulSoup(''.join(soup.find_all(string=lambda text: isinstance(text, Comment) and '<table' in text)))\n",
    "        soupTables.find(\"tr\", class_=\"over_header\").decompose()\n",
    "        dpoy_table = soupTables.find('table', id=\"dpoy\")\n",
    "        dpoy_df = pd.read_html(str(dpoy_table))[0]\n",
    "        dpoy_df['Year'] = year\n",
    "        dpoy_list.append(dpoy_df)\n",
    "\n",
    "dpoy_data = pd.concat(dpoy_list)\n",
    "dpoy_data.reset_index(drop=True)\n",
    "dpoy_data.to_csv('MVP_data/dpoy_awards.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting SMOY candidates from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoy_list = []\n",
    "for year in years:\n",
    "    with open(f'MVP_data/{year}.html', errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        soupTables = BeautifulSoup(''.join(soup.find_all(string=lambda text: isinstance(text, Comment) and '<table' in text)))\n",
    "        smoy_table = soupTables.find('table', id=\"smoy\")\n",
    "        smoy_df = pd.read_html(str(smoy_table), header=1)[0]\n",
    "        smoy_df['Year'] = year\n",
    "        smoy_list.append(smoy_df)\n",
    "\n",
    "smoy_data = pd.concat(smoy_list)\n",
    "smoy_data.reset_index(drop=True)\n",
    "smoy_data.to_csv('MVP_data/smoy_awards.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Selenium to extract player PPG, Advanced, and Team Record stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
