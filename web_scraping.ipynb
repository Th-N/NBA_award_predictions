{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import requests\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Requests and BeautifulSoup to scrape NBA data for players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2000, 2003))\n",
    "ppg_url = \"https://www.basketball-reference.com/leagues/NBA_{}_ppg.html\"\n",
    "advanced_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_advanced.html\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape MVP awards table from 2000-2023 and save as an HTML file\n",
    "for year in years:\n",
    "    base_url = f\"https://www.basketball-reference.com/awards/awards_{year}.html\"\n",
    "    data = requests.get(base_url)\n",
    "\n",
    "    with open(f'MVP_Data/{year}.html', 'w+', encoding=\"utf-8\") as f:\n",
    "        f.write(data.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting MVP candidates from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open each HTML file, parse out the table, create pandas dataframe\n",
    "mvp_list = []\n",
    "for year in years:\n",
    "    with open(f\"MVP_data/{year}.html\", errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        remove_header = soup.find(\"tr\", class_='over_header').decompose()\n",
    "        mvp_table = soup.find(id='mvp')\n",
    "        mvp_df = pd.read_html(str(mvp_table))[0]\n",
    "        mvp_df['Year'] = year\n",
    "        mvp_list.append(mvp_df)\n",
    "\n",
    "mvp_data = pd.concat(mvp_list)\n",
    "mvp_data.reset_index(drop=True)\n",
    "mvp_data.to_csv(f'MVP_data/mvp_awards.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting ROY candidates from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "roy_list = []\n",
    "for year in years:\n",
    "    with open(f\"MVP_data/{year}.html\", errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        remove_header = soup.find(\"tr\", class_='over_header').decompose()\n",
    "        roy_table = soup.find(id='roy')\n",
    "        roy_df = pd.read_html(str(roy_table),header=1)[0]\n",
    "        roy_df['Year'] = year\n",
    "        roy_list.append(roy_df)\n",
    "\n",
    "roy_data = pd.concat(roy_list)\n",
    "roy_data.reset_index(drop=True)\n",
    "roy_data.to_csv(f'MVP_data/roy_awards.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting DPOY candidates from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open each HTML file, parse out the table, create pandas dataframe\n",
    "dpoy_list = []\n",
    "for year in years:\n",
    "    with open(f'MVP_data/{year}.html', errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        soupTables = BeautifulSoup(''.join(soup.find_all(string=lambda text: isinstance(text, Comment) and '<table' in text)))\n",
    "        soupTables.find(\"tr\", class_=\"over_header\").decompose()\n",
    "        dpoy_table = soupTables.find('table', id=\"dpoy\")\n",
    "        dpoy_df = pd.read_html(str(dpoy_table))[0]\n",
    "        dpoy_df['Year'] = year\n",
    "        dpoy_list.append(dpoy_df)\n",
    "\n",
    "dpoy_data = pd.concat(dpoy_list)\n",
    "dpoy_data.reset_index(drop=True)\n",
    "dpoy_data.to_csv('MVP_data/dpoy_awards.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting SMOY candidates from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoy_list = []\n",
    "for year in years:\n",
    "    with open(f'MVP_data/{year}.html', errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        soupTables = BeautifulSoup(''.join(soup.find_all(string=lambda text: isinstance(text, Comment) and '<table' in text)))\n",
    "        smoy_table = soupTables.find('table', id=\"smoy\")\n",
    "        smoy_df = pd.read_html(str(smoy_table), header=1)[0]\n",
    "        smoy_df['Year'] = year\n",
    "        smoy_list.append(smoy_df)\n",
    "\n",
    "smoy_data = pd.concat(smoy_list)\n",
    "smoy_data.reset_index(drop=True)\n",
    "smoy_data.to_csv('MVP_data/smoy_awards.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Selenium to extract player PPG, Advanced, and Team Record stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBA Season 2000 successfully saved.\n",
      "NBA Season 2001 successfully saved.\n",
      "NBA Season 2002 successfully saved.\n",
      "NBA Season 2003 successfully saved.\n",
      "NBA Season 2004 successfully saved.\n",
      "NBA Season 2005 successfully saved.\n",
      "NBA Season 2006 successfully saved.\n",
      "NBA Season 2007 successfully saved.\n",
      "NBA Season 2008 successfully saved.\n",
      "NBA Season 2009 successfully saved.\n",
      "NBA Season 2010 successfully saved.\n",
      "NBA Season 2011 successfully saved.\n",
      "NBA Season 2012 successfully saved.\n",
      "NBA Season 2013 successfully saved.\n",
      "NBA Season 2014 successfully saved.\n",
      "NBA Season 2015 successfully saved.\n",
      "NBA Season 2016 successfully saved.\n",
      "NBA Season 2017 successfully saved.\n",
      "NBA Season 2018 successfully saved.\n",
      "NBA Season 2019 successfully saved.\n",
      "NBA Season 2020 successfully saved.\n",
      "NBA Season 2021 successfully saved.\n",
      "NBA Season 2022 successfully saved.\n",
      "NBA Season 2023 successfully saved.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "for year in years:\n",
    "    driver.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\")\n",
    "    time.sleep(5)\n",
    "    pagesource = driver.page_source \n",
    "\n",
    "    with open(f'NBA_Stats/ppg_{year}.html', 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(pagesource)\n",
    "    print(f\"NBA Season {year} successfully saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tariq Abdul-Wahad</td>\n",
       "      <td>SG</td>\n",
       "      <td>25</td>\n",
       "      <td>TOT</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>25.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tariq Abdul-Wahad</td>\n",
       "      <td>SG</td>\n",
       "      <td>25</td>\n",
       "      <td>ORL</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>26.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Tariq Abdul-Wahad</td>\n",
       "      <td>SG</td>\n",
       "      <td>25</td>\n",
       "      <td>DEN</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>24.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Shareef Abdur-Rahim</td>\n",
       "      <td>SF</td>\n",
       "      <td>23</td>\n",
       "      <td>VAN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>39.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Cory Alexander</td>\n",
       "      <td>PG</td>\n",
       "      <td>26</td>\n",
       "      <td>DEN</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14418</th>\n",
       "      <td>535</td>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>PF</td>\n",
       "      <td>34</td>\n",
       "      <td>TOR</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14419</th>\n",
       "      <td>536</td>\n",
       "      <td>Trae Young</td>\n",
       "      <td>PG</td>\n",
       "      <td>24</td>\n",
       "      <td>ATL</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>34.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14420</th>\n",
       "      <td>537</td>\n",
       "      <td>Omer Yurtseven</td>\n",
       "      <td>C</td>\n",
       "      <td>24</td>\n",
       "      <td>MIA</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14421</th>\n",
       "      <td>538</td>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>C</td>\n",
       "      <td>30</td>\n",
       "      <td>MIA</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14422</th>\n",
       "      <td>539</td>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>LAC</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>28.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14423 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rk               Player Pos  Age   Tm   G  GS    MP   FG   FGA  ...  \\\n",
       "0        1    Tariq Abdul-Wahad  SG   25  TOT  61  56  25.9  4.5  10.6  ...   \n",
       "1        1    Tariq Abdul-Wahad  SG   25  ORL  46  46  26.2  4.8  11.2  ...   \n",
       "2        1    Tariq Abdul-Wahad  SG   25  DEN  15  10  24.9  3.4   8.7  ...   \n",
       "3        2  Shareef Abdur-Rahim  SF   23  VAN  82  82  39.3  7.2  15.6  ...   \n",
       "4        3       Cory Alexander  PG   26  DEN  29   2  11.3  1.0   3.4  ...   \n",
       "...    ...                  ...  ..  ...  ...  ..  ..   ...  ...   ...  ...   \n",
       "14418  535       Thaddeus Young  PF   34  TOR  54   9  14.7  2.0   3.7  ...   \n",
       "14419  536           Trae Young  PG   24  ATL  73  73  34.8  8.2  19.0  ...   \n",
       "14420  537       Omer Yurtseven   C   24  MIA   9   0   9.2  1.8   3.0  ...   \n",
       "14421  538          Cody Zeller   C   30  MIA  15   2  14.5  2.5   3.9  ...   \n",
       "14422  539          Ivica Zubac   C   25  LAC  76  76  28.6  4.3   6.8  ...   \n",
       "\n",
       "       ORB  DRB   TRB   AST  STL  BLK  TOV   PF   PTS  Year  \n",
       "0      1.7  3.1   4.8   1.6  1.0  0.5  1.7  2.4  11.4  2000  \n",
       "1      1.7  3.5   5.2   1.6  1.2  0.3  1.9  2.5  12.2  2000  \n",
       "2      1.6  1.9   3.5   1.7  0.4  0.8  1.3  2.1   8.9  2000  \n",
       "3      2.7  7.4  10.1   3.3  1.1  1.1  3.0  3.0  20.3  2000  \n",
       "4      0.3  1.2   1.4   2.0  0.8  0.1  1.0  1.3   2.8  2000  \n",
       "...    ...  ...   ...   ...  ...  ...  ...  ...   ...   ...  \n",
       "14418  1.3  1.8   3.1   1.4  1.0  0.1  0.8  1.6   4.4  2023  \n",
       "14419  0.8  2.2   3.0  10.2  1.1  0.1  4.1  1.4  26.2  2023  \n",
       "14420  0.9  1.7   2.6   0.2  0.2  0.2  0.4  1.8   4.4  2023  \n",
       "14421  1.7  2.6   4.3   0.7  0.2  0.3  0.9  2.2   6.5  2023  \n",
       "14422  3.1  6.8   9.9   1.0  0.4  1.3  1.5  2.9  10.8  2023  \n",
       "\n",
       "[14423 rows x 31 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg_list = []\n",
    "for year in years:\n",
    "    with open(f'NBA_Stats/ppg_{year}.html', 'r', errors=\"ignore\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        for item in soup.find_all(\"tr\", class_=\"thead\"):\n",
    "            item.decompose()\n",
    "        ppg_table = soup.find(id=\"per_game_stats\")\n",
    "        ppg_df = pd.read_html(str(ppg_table))[0]\n",
    "        ppg_df['Year'] = year\n",
    "        ppg_list.append(ppg_df)\n",
    "\n",
    "ppg_data = pd.concat(ppg_list)\n",
    "ppg_data.reset_index(drop=True)\n",
    "ppg_data.to_csv('NBA_Stats/ppg_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_scraping(years, url, metric=\"\"):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "\n",
    "    for year in years:\n",
    "        driver.get(url.format(year))\n",
    "        time.sleep(5)\n",
    "        pagesource = driver.page_source \n",
    "\n",
    "        with open(f'NBA_Stats/{metric}_{year}.html', 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(pagesource)\n",
    "        print(f\"NBA Season {year} successfully saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBA Season 2000 successfully saved.\n",
      "NBA Season 2001 successfully saved.\n",
      "NBA Season 2002 successfully saved.\n"
     ]
    }
   ],
   "source": [
    "stats_scraping(years, advanced_stats_url, \"advanced_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
